{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filepath=os.path.abspath(os.getcwd())+\"\\\\feature_matrix\\\\Combined Data CSV.csv\" # Code assumes it is found in Postural_sway_measures / Change name of csv file as needed\n",
    "data=pd.read_csv(filepath,sep=',')\n",
    "data=data.set_index('name')\n",
    "data['sex']=(data['sex'] == 'male').astype(int) # 1 for male and 0 for female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predictors \n",
    "# layer 1: [0]=\"1\" / [1]=\"2\" \n",
    "data['layer 1']=(data['layer 1'] == 2).astype(int) # 1 for \"2\" in layer1 and 0 for \"1\" in layer1\n",
    "# layer 2: [0,0]=\"1\" / [1,0]=\"3\" / [0,1]=\"4\"\n",
    "data.insert(5,\"layer 2-2\",data['layer 2'])\n",
    "data['layer 2']=(data['layer 2'] == 3).astype(int) # 1 for \"3\" in layer2\n",
    "data['layer 2-2']=(data['layer 2-2'] == 4).astype(int) # 1 for \"4\" in layer2\n",
    "# layer 3: [0,0,0]=\"1\" / [1,0,0]=\"4\" / [0,1,0]=\"5\" / [0,0,1]=\"6\"\n",
    "data.insert(7,\"layer 3-2\",data['layer 3'])\n",
    "data.insert(8,\"layer 3-3\",data['layer 3'])\n",
    "data['layer 3']=(data['layer 3'] == 4).astype(int) # 1 for \"4\" in layer2\n",
    "data['layer 3-2']=(data['layer 3-2'] == 5).astype(int) # 1 for \"5\" in layer2\n",
    "data['layer 3-3']=(data['layer 3-3'] == 6).astype(int) # 1 for \"6\" in layer2\n",
    "\n",
    "## Data Division\n",
    "young_data=data.drop(data[data.age>=65].index)\n",
    "old_data=data.drop(data[data.age<65].index)\n",
    "\n",
    "## Features\n",
    "all_features=list(data.columns[0:2])+list(data.columns[9:]) # all features, not including the diagnosis\n",
    "features=all_features[:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'age',\n",
       " 'Open eye pressure center position (left and right)',\n",
       " 'Center position of the eye pressure (front and back)',\n",
       " 'Eye circumference area',\n",
       " 'Eye opening effective value area',\n",
       " 'Total eye-open path length',\n",
       " 'Eye opening unit area locus length',\n",
       " 'Eye opening average speed',\n",
       " 'Closed foot pressure center position (left and right)',\n",
       " 'Eye pressure center position (front and back)',\n",
       " 'Peripheral area with eyes closed',\n",
       " 'Eye closing effective value area',\n",
       " 'Total eye-closure length',\n",
       " 'Eye-closing unit area locus length',\n",
       " 'Eye closing average speed',\n",
       " 'Romberg rate (peripheral area)',\n",
       " 'Romberg rate (total track length)',\n",
       " 'Romberg rate (average speed)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## (!!! LAYER 1 !!!)\n",
    "features=all_features[:]\n",
    "diagnosis=data['layer 1']\n",
    "\n",
    "# Most Correlated Features\n",
    "spearman_correlations=data[features].corrwith(diagnosis,method='spearman')\n",
    "features_layer1=[]\n",
    "minimum=0.2 # Change this for different results\n",
    "for i in range(len(spearman_correlations)):\n",
    "    if abs(spearman_correlations[i])>minimum:\n",
    "        features_layer1.append(spearman_correlations.index[i])\n",
    "#features=features_layer1\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d05dffb4493f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdiagnosis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\rfe.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    512\u001b[0m         scores = parallel(\n\u001b[0;32m    513\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\rfe.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((train, test))\u001b[0m\n\u001b[0;32m    512\u001b[0m         scores = parallel(\n\u001b[0;32m    513\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\rfe.pyc\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     return rfe._fit(\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\rfe.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Feature Ranking (SVR)\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFECV(estimator,step=1,cv=5)\n",
    "selector = selector.fit(data[features],diagnosis)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Ranking (RF)\n",
    "from sklearn.feature_selection import RFECV\n",
    "estimator = RandomForestClassifier(random_state=42, warm_start=True, n_jobs=-1)\n",
    "selector = RFECV(estimator,step=1,cv=5)\n",
    "selector = selector.fit(data[features],diagnosis)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Ranking (SVC)\n",
    "from sklearn.feature_selection import RFECV\n",
    "estimator = LinearSVC()\n",
    "selector = RFECV(estimator,step=1,cv=5)\n",
    "selector = selector.fit(data[features],diagnosis)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Results:\n",
      "TP=79 / FP=43 / TN=76 / FN=23 \n",
      "Accuracy = 0.701357  \n",
      "Sensitivity = 0.774510 \n",
      "Specificity = 0.638655 \n",
      "Precision = 0.647541\n"
     ]
    }
   ],
   "source": [
    "# SVC: Train-Test Split \n",
    "LSVC=LinearSVC()\n",
    "scaler=RobustScaler()\n",
    "scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "scaler.fit(scaled_train)\n",
    "scaled_train=scaler.transform(scaled_train)\n",
    "scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "LSVC=LSVC.fit(scaled_train,diagnosis_train)\n",
    "diagnosis_predictions=LSVC.predict(scaled_test)\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "for i in range(len(diagnosis_test)):   \n",
    "    if diagnosis_test[i]==diagnosis_predictions[i]==1:\n",
    "        TP=TP+1\n",
    "    elif diagnosis_test[i]==diagnosis_predictions[i]==0:\n",
    "        TN=TN+1\n",
    "    elif diagnosis_test[i]==1 and diagnosis_predictions[i]==0:\n",
    "        FP=FP+1\n",
    "    elif diagnosis_test[i]==0 and diagnosis_predictions[i]==1:\n",
    "        FN=FN+1\n",
    "Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "Sensitivity=TP/(TP+FN)\n",
    "Specificity=TN/(TN+FP)\n",
    "Precision=TP/(TP+FP)\n",
    "print(\"Train-Test Split Results:\\nTP=%d / FP=%d / TN=%d / FN=%d \\nAccuracy = %f  \\nSensitivity = %f \\nSpecificity = %f \\nPrecision = %f\" %(TP,FP,TN,FN,Accuracy,Sensitivity,Specificity,Precision))\n",
    "best_accuracy=Accuracy\n",
    "best_precision=Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A\n",
      "['age', 'Center position of the eye pressure (front and back)', 'Eye circumference area', 'Eye opening effective value area', 'Total eye-open path length', 'Closed foot pressure center position (left and right)', 'Eye pressure center position (front and back)', 'Peripheral area with eyes closed', 'Eye closing effective value area', 'Total eye-closure length', 'Eye-closing unit area locus length', 'Eye closing average speed', 'Romberg rate (peripheral area)', 'Romberg rate (total track length)', 'Romberg rate (average speed)']\n"
     ]
    }
   ],
   "source": [
    "# SVC: Train-Test Split (Ranking) \n",
    "loops=len(features)-1\n",
    "check=True\n",
    "iteration=0\n",
    "feature_list=features[:]\n",
    "removed_features=[]\n",
    "while(iteration<loops and check==True):\n",
    "    iteration=iteration+1\n",
    "    accuracies=[]\n",
    "    precisions=[]\n",
    "    final_list=feature_list[:]\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_list=final_list[:]\n",
    "        del feature_list[i]\n",
    "        LSVC=LinearSVC()\n",
    "        scaler=RobustScaler()\n",
    "        scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[feature_list], diagnosis,test_size=0.3, random_state=42)\n",
    "        scaler.fit(scaled_train)\n",
    "        scaled_train=scaler.transform(scaled_train)\n",
    "        scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "        LSVC=LSVC.fit(scaled_train,diagnosis_train)\n",
    "        diagnosis_predictions=LSVC.predict(scaled_test)\n",
    "\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        for j in range(len(diagnosis_test)):   \n",
    "            if diagnosis_test[j]==diagnosis_predictions[j]==1:\n",
    "                TP=TP+1\n",
    "            elif diagnosis_test[j]==diagnosis_predictions[j]==0:\n",
    "                TN=TN+1\n",
    "            elif diagnosis_test[j]==1 and diagnosis_predictions[j]==0:\n",
    "                FP=FP+1\n",
    "            elif diagnosis_test[j]==0 and diagnosis_predictions[j]==1:\n",
    "                FN=FN+1\n",
    "        Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "        #Sensitivity=TP/(TP+FN)\n",
    "        #Specificity=TN/(TN+FP)\n",
    "        Precision=TP/(TP+FP)\n",
    "        accuracies.append(Accuracy)\n",
    "        precisions.append(Precision)\n",
    "    if(max(accuracies)>best_accuracy):\n",
    "        best_accuracy=max(accuracies)\n",
    "        best_precision=precisions[accuracies.index(max(accuracies))]\n",
    "        feature_list=final_list[:]\n",
    "        removed_features.append(feature_list[accuracies.index(max(accuracies))])\n",
    "        del feature_list[accuracies.index(max(accuracies))]\n",
    "    else:\n",
    "        print(\"N/A\")\n",
    "        check=False\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.755656108597\n",
      "0.72131147541\n",
      "['sex', 'Open eye pressure center position (left and right)', 'Eye opening unit area locus length', 'Eye opening average speed']\n"
     ]
    }
   ],
   "source": [
    "print(iteration)\n",
    "print(best_accuracy)\n",
    "print(best_precision)\n",
    "print(removed_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Results:\n",
      "TP=87 / FP=35 / TN=79 / FN=20 \n",
      "Accuracy = 0.751131  \n",
      "Sensitivity = 0.813084 \n",
      "Specificity = 0.692982 \n",
      "Precision = 0.713115\n"
     ]
    }
   ],
   "source": [
    "# ////////////////////////////////////////////////////////////\n",
    "LSVC=LinearSVC()\n",
    "scaler=RobustScaler()\n",
    "scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[final_list], diagnosis,test_size=0.3, random_state=42)\n",
    "scaler.fit(scaled_train)\n",
    "scaled_train=scaler.transform(scaled_train)\n",
    "scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "LSVC=LSVC.fit(scaled_train,diagnosis_train)\n",
    "diagnosis_predictions=LSVC.predict(scaled_test)\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "for i in range(len(diagnosis_test)):   \n",
    "    if diagnosis_test[i]==diagnosis_predictions[i]==1:\n",
    "        TP=TP+1\n",
    "    elif diagnosis_test[i]==diagnosis_predictions[i]==0:\n",
    "        TN=TN+1\n",
    "    elif diagnosis_test[i]==1 and diagnosis_predictions[i]==0:\n",
    "        FP=FP+1\n",
    "    elif diagnosis_test[i]==0 and diagnosis_predictions[i]==1:\n",
    "        FN=FN+1\n",
    "Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "Sensitivity=TP/(TP+FN)\n",
    "Specificity=TN/(TN+FP)\n",
    "Precision=TP/(TP+FP)\n",
    "print(\"Train-Test Split Results:\\nTP=%d / FP=%d / TN=%d / FN=%d \\nAccuracy = %f  \\nSensitivity = %f \\nSpecificity = %f \\nPrecision = %f\" %(TP,FP,TN,FN,Accuracy,Sensitivity,Specificity,Precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Results:\n",
      "TP=79 / FP=43 / TN=82 / FN=17 \n",
      "Accuracy = 0.728507  \n",
      "Sensitivity = 0.822917 \n",
      "Specificity = 0.656000 \n",
      "Precision = 0.647541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Alternative SVC: Train-Test Split\n",
    "LSVC=SVC(kernel='rbf')\n",
    "scaler=RobustScaler()\n",
    "scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "scaler.fit(scaled_train)\n",
    "scaled_train=scaler.transform(scaled_train)\n",
    "scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "LSVC=LSVC.fit(scaled_train,diagnosis_train)\n",
    "diagnosis_predictions=LSVC.predict(scaled_test)\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "for i in range(len(diagnosis_test)):   \n",
    "    if diagnosis_test[i]==diagnosis_predictions[i]==1:\n",
    "        TP=TP+1\n",
    "    elif diagnosis_test[i]==diagnosis_predictions[i]==0:\n",
    "        TN=TN+1\n",
    "    elif diagnosis_test[i]==1 and diagnosis_predictions[i]==0:\n",
    "        FP=FP+1\n",
    "    elif diagnosis_test[i]==0 and diagnosis_predictions[i]==1:\n",
    "        FN=FN+1\n",
    "Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "Sensitivity=TP/(TP+FN)\n",
    "Specificity=TN/(TN+FP)\n",
    "Precision=TP/(TP+FP)\n",
    "print(\"Train-Test Split Results:\\nTP=%d / FP=%d / TN=%d / FN=%d \\nAccuracy = %f  \\nSensitivity = %f \\nSpecificity = %f \\nPrecision = %f\" %(TP,FP,TN,FN,Accuracy,Sensitivity,Specificity,Precision))\n",
    "best_accuracy=Accuracy\n",
    "best_precision=Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A\n",
      "['sex', 'age', 'Open eye pressure center position (left and right)', 'Center position of the eye pressure (front and back)', 'Eye circumference area', 'Eye opening effective value area', 'Total eye-open path length', 'Eye opening unit area locus length', 'Eye opening average speed', 'Closed foot pressure center position (left and right)', 'Eye pressure center position (front and back)', 'Peripheral area with eyes closed', 'Eye closing effective value area', 'Total eye-closure length', 'Eye-closing unit area locus length', 'Eye closing average speed', 'Romberg rate (peripheral area)', 'Romberg rate (total track length)', 'Romberg rate (average speed)']\n"
     ]
    }
   ],
   "source": [
    "# Alternative SVC: Train-Test Split (Ranking) \n",
    "loops=len(features)-1\n",
    "check=True\n",
    "iteration=0\n",
    "feature_list=features[:]\n",
    "removed_features=[]\n",
    "while(iteration<loops and check==True):\n",
    "    iteration=iteration+1\n",
    "    accuracies=[]\n",
    "    precisions=[]\n",
    "    final_list=feature_list[:]\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_list=final_list[:]\n",
    "        del feature_list[i]\n",
    "        LSVC=SVC(kernel='rbf')\n",
    "        scaler=RobustScaler()\n",
    "        scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "        scaler.fit(scaled_train)\n",
    "        scaled_train=scaler.transform(scaled_train)\n",
    "        scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "        LSVC=LSVC.fit(scaled_train,diagnosis_train)\n",
    "        diagnosis_predictions=LSVC.predict(scaled_test)\n",
    "\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        for j in range(len(diagnosis_test)):   \n",
    "            if diagnosis_test[j]==diagnosis_predictions[j]==1:\n",
    "                TP=TP+1\n",
    "            elif diagnosis_test[j]==diagnosis_predictions[j]==0:\n",
    "                TN=TN+1\n",
    "            elif diagnosis_test[j]==1 and diagnosis_predictions[j]==0:\n",
    "                FP=FP+1\n",
    "            elif diagnosis_test[j]==0 and diagnosis_predictions[j]==1:\n",
    "                FN=FN+1\n",
    "        Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "        #Sensitivity=TP/(TP+FN)\n",
    "        #Specificity=TN/(TN+FP)\n",
    "        Precision=TP/(TP+FP)\n",
    "        accuracies.append(Accuracy)\n",
    "        precisions.append(Precision)\n",
    "    if(max(accuracies)>best_accuracy):\n",
    "        best_accuracy=max(accuracies)\n",
    "        best_precision=precisions[accuracies.index(max(accuracies))]\n",
    "        feature_list=final_list[:]\n",
    "        removed_features.append(feature_list[accuracies.index(max(accuracies))])\n",
    "        del feature_list[accuracies.index(max(accuracies))]\n",
    "    else:\n",
    "        print(\"N/A\")\n",
    "        check=False\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.72850678733\n",
      "0.647540983607\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(iteration)\n",
    "print(best_accuracy)\n",
    "print(best_precision)\n",
    "print(removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Results:\n",
      "TP=81 / FP=41 / TN=71 / FN=28 \n",
      "Accuracy = 0.687783  \n",
      "Sensitivity = 0.743119 \n",
      "Specificity = 0.633929 \n",
      "Precision = 0.663934\n"
     ]
    }
   ],
   "source": [
    "# K-nearest Neighbors: Train-Test Split\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "scaler=RobustScaler()\n",
    "scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "scaler.fit(scaled_train)\n",
    "scaled_train=scaler.transform(scaled_train)\n",
    "scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "neigh.fit(scaled_train,diagnosis_train)\n",
    "diagnosis_predictions=neigh.predict(scaled_test)\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "for i in range(len(diagnosis_test)):   \n",
    "    if diagnosis_test[i]==diagnosis_predictions[i]==1:\n",
    "        TP=TP+1\n",
    "    elif diagnosis_test[i]==diagnosis_predictions[i]==0:\n",
    "        TN=TN+1\n",
    "    elif diagnosis_test[i]==1 and diagnosis_predictions[i]==0:\n",
    "        FP=FP+1\n",
    "    elif diagnosis_test[i]==0 and diagnosis_predictions[i]==1:\n",
    "        FN=FN+1\n",
    "Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "Sensitivity=TP/(TP+FN)\n",
    "Specificity=TN/(TN+FP)\n",
    "Precision=TP/(TP+FP)\n",
    "print(\"Train-Test Split Results:\\nTP=%d / FP=%d / TN=%d / FN=%d \\nAccuracy = %f  \\nSensitivity = %f \\nSpecificity = %f \\nPrecision = %f\" %(TP,FP,TN,FN,Accuracy,Sensitivity,Specificity,Precision))\n",
    "best_accuracy=Accuracy\n",
    "best_precision=Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A\n",
      "['sex', 'age', 'Open eye pressure center position (left and right)', 'Center position of the eye pressure (front and back)', 'Eye circumference area', 'Eye opening effective value area', 'Total eye-open path length', 'Eye opening unit area locus length', 'Eye opening average speed', 'Closed foot pressure center position (left and right)', 'Eye pressure center position (front and back)', 'Peripheral area with eyes closed', 'Eye closing effective value area', 'Total eye-closure length', 'Eye-closing unit area locus length', 'Eye closing average speed', 'Romberg rate (peripheral area)', 'Romberg rate (total track length)', 'Romberg rate (average speed)']\n"
     ]
    }
   ],
   "source": [
    "# K-nearest Neighbor: Train-Test Split (Ranking) \n",
    "loops=len(features)-1\n",
    "check=True\n",
    "iteration=0\n",
    "feature_list=features[:]\n",
    "removed_features=[]\n",
    "while(iteration<loops and check==True):\n",
    "    iteration=iteration+1\n",
    "    accuracies=[]\n",
    "    precisions=[]\n",
    "    final_list=feature_list[:]\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_list=final_list[:]\n",
    "        del feature_list[i]\n",
    "        neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "        scaler=RobustScaler()\n",
    "        scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "        scaler.fit(scaled_train)\n",
    "        scaled_train=scaler.transform(scaled_train)\n",
    "        scaled_test=scaler.transform(scaled_test)\n",
    "\n",
    "        neigh.fit(scaled_train,diagnosis_train)\n",
    "        diagnosis_predictions=neigh.predict(scaled_test)\n",
    "\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        for j in range(len(diagnosis_test)):   \n",
    "            if diagnosis_test[j]==diagnosis_predictions[j]==1:\n",
    "                TP=TP+1\n",
    "            elif diagnosis_test[j]==diagnosis_predictions[j]==0:\n",
    "                TN=TN+1\n",
    "            elif diagnosis_test[j]==1 and diagnosis_predictions[j]==0:\n",
    "                FP=FP+1\n",
    "            elif diagnosis_test[j]==0 and diagnosis_predictions[j]==1:\n",
    "                FN=FN+1\n",
    "        Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "        #Sensitivity=TP/(TP+FN)\n",
    "        #Specificity=TN/(TN+FP)\n",
    "        Precision=TP/(TP+FP)\n",
    "        accuracies.append(Accuracy)\n",
    "        precisions.append(Precision)\n",
    "    if(max(accuracies)>best_accuracy):\n",
    "        best_accuracy=max(accuracies)\n",
    "        best_precision=precisions[accuracies.index(max(accuracies))]\n",
    "        feature_list=final_list[:]\n",
    "        removed_features.append(feature_list[accuracies.index(max(accuracies))])\n",
    "        del feature_list[accuracies.index(max(accuracies))]\n",
    "    else:\n",
    "        print(\"N/A\")\n",
    "        check=False\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.68778280543\n",
      "0.66393442623\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(iteration)\n",
    "print(best_accuracy)\n",
    "print(best_precision)\n",
    "print(removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Results:\n",
      "TP=71 / FP=51 / TN=82 / FN=17 \n",
      "Accuracy = 0.692308  \n",
      "Sensitivity = 0.806818 \n",
      "Specificity = 0.616541 \n",
      "Precision = 0.581967\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: Train-Test Split\n",
    "scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "RF = RandomForestClassifier(random_state=42, warm_start=True, n_jobs=-1)\n",
    "#RF.set_params(n_estimators=100) # Tree number\n",
    "RF.fit(scaled_train,diagnosis_train)\n",
    "diagnosis_predictions=RF.predict(scaled_test)\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "for i in range(len(diagnosis_test)): \n",
    "    if diagnosis_test[i]==diagnosis_predictions[i]==1:\n",
    "        TP=TP+1\n",
    "    elif diagnosis_test[i]==diagnosis_predictions[i]==0:\n",
    "        TN=TN+1\n",
    "    elif diagnosis_test[i]==1 and diagnosis_predictions[i]==0:\n",
    "        FP=FP+1\n",
    "    elif diagnosis_test[i]==0 and diagnosis_predictions[i]==1:\n",
    "        FN=FN+1\n",
    "Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "Sensitivity=TP/(TP+FN)\n",
    "Specificity=TN/(TN+FP)\n",
    "Precision=TP/(TP+FP)\n",
    "print(\"Train-Test Split Results:\\nTP=%d / FP=%d / TN=%d / FN=%d \\nAccuracy = %f  \\nSensitivity = %f \\nSpecificity = %f \\nPrecision = %f\" %(TP,FP,TN,FN,Accuracy,Sensitivity,Specificity,Precision))\n",
    "best_accuracy=Accuracy\n",
    "best_precision=Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N//A\n",
      "['sex', 'age', 'Open eye pressure center position (left and right)', 'Center position of the eye pressure (front and back)', 'Eye circumference area', 'Eye opening effective value area', 'Total eye-open path length', 'Eye opening unit area locus length', 'Eye opening average speed', 'Closed foot pressure center position (left and right)', 'Eye pressure center position (front and back)', 'Peripheral area with eyes closed', 'Eye closing effective value area', 'Total eye-closure length', 'Eye-closing unit area locus length', 'Eye closing average speed', 'Romberg rate (peripheral area)', 'Romberg rate (total track length)', 'Romberg rate (average speed)']\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: Train-Test Split (Ranking) \n",
    "loops=len(features)-1\n",
    "check=True\n",
    "iteration=0\n",
    "feature_list=features[:]\n",
    "removed_features=[]\n",
    "while(iteration<loops and check==True):\n",
    "    iteration=iteration+1\n",
    "    accuracies=[]\n",
    "    precisions=[]\n",
    "    final_list=feature_list[:]\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_list=final_list[:]\n",
    "        del feature_list[i]\n",
    "        scaled_train, scaled_test, diagnosis_train, diagnosis_test = train_test_split(data[features], diagnosis,test_size=0.3, random_state=42)\n",
    "        RF = RandomForestClassifier(random_state=42, warm_start=True, n_jobs=-1)\n",
    "        RF.fit(scaled_train,diagnosis_train)\n",
    "        diagnosis_predictions=RF.predict(scaled_test)\n",
    "\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        for j in range(len(diagnosis_test)):   \n",
    "            if diagnosis_test[j]==diagnosis_predictions[j]==1:\n",
    "                TP=TP+1\n",
    "            elif diagnosis_test[j]==diagnosis_predictions[j]==0:\n",
    "                TN=TN+1\n",
    "            elif diagnosis_test[j]==1 and diagnosis_predictions[j]==0:\n",
    "                FP=FP+1\n",
    "            elif diagnosis_test[j]==0 and diagnosis_predictions[j]==1:\n",
    "                FN=FN+1\n",
    "        Accuracy=(TP+TN)/(len(diagnosis_test))\n",
    "        #Sensitivity=TP/(TP+FN)\n",
    "        #Specificity=TN/(TN+FP)\n",
    "        Precision=TP/(TP+FP)\n",
    "        accuracies.append(Accuracy)\n",
    "        precisions.append(Precision)\n",
    "    if(max(accuracies)>best_accuracy):\n",
    "        best_accuracy=max(accuracies)\n",
    "        best_precision=precisions[accuracies.index(max(accuracies))]\n",
    "        feature_list=final_list[:]\n",
    "        removed_features.append(feature_list[accuracies.index(max(accuracies))])\n",
    "        del feature_list[accuracies.index(max(accuracies))]\n",
    "    else:\n",
    "        print(\"N/A\")\n",
    "        check=False\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.692307692308\n",
      "0.581967213115\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(iteration)\n",
    "print(best_accuracy)\n",
    "print(best_precision)\n",
    "print(removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
